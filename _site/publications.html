<!DOCTYPE html>
<html lang="">
  <head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  <title>Publications | JAEYOON SIM</title>
  <link rel="stylesheet" href="/assets/libs/bootstrap/bootstrap.min.css">
  <script defer src="/assets/libs/fontawesome/all.min.js"></script>
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/apple-icon-152x152.png">
  <!-- <link rel="shortcut icon" href="/assets/favicon.ico"> -->
  <link rel="shortcut icon" href="/assets/face.png">
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">
  <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.min.css"
    />
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
</head>

  <body>
    <div>
      <!--
      <div class="bird-container bird-container--one">
        <div class="bird bird--one"></div>
      </div>
      
      <div class="bird-container bird-container--two">
        <div class="bird bird--two"></div>
      </div>
      
      <div class="bird-container bird-container--three">
        <div class="bird bird--three"></div>
      </div>
      
      <div class="bird-container bird-container--four">
        <div class="bird bird--four"></div>
      </div>
    </div>
    -->
    <div class="col-lg-8 mx-auto p-3 py-md-5">
      <header class="mb-4 border-bottom">

  <script src="https://kit.fontawesome.com/b5e768b1dd.js" crossorigin="anonymous"></script>
  <script src="/main.js" defer></script>

  <nav class="navbar_header">
    
    <div class="navbar_header_logo">
      <a href="/" style="text-decoration:none">
        <span class="main_logo_1 fs-4">CLAUDE</span>
        <span class="main_logo_2 fs-4">SSIM</span>
      </a>
      <i class="navbar_header_logo_image fab fa-accusoft fs-4"></i>
    </div>

    <ul class="navbar_header_menu">
      
      <li><a href="/cv" style="text-decoration:none">ABOUT ME</a></li>
      
      <li><a href="/publications" style="text-decoration:none">PUBLICATIONS</a></li>
      
      <li><a href="/contact" style="text-decoration:none">CONTACT</a></li>
      
    </ul>

    <a href="#" class="navbar_header_toggleBtn">
      <i class="fas fa-bars"></i>
    </a>

  </nav>
</header>

      


<!-- Publications -->
<script src="/main.js" defer></script>



<div class="row g-5 mb-5">
  <div>
    <h3 class="main_title pb-3 mb-5">Publications</h3>
    <script async defer src="https://buttons.github.io/buttons.js"></script>

<!-- International Conference -->
    <div class="row g-5 mb-5">
      <div class="categorybar col-md-2">
        <h6>International</h6>
        <i class="fas fa-sync fa-spin"></i>
      </div>
      <div class="detail_publication col-md-10">
        <div class="row g-5 mb-5">
          
          <div class="col-lg-4 text-center">
            <img id="publication_image"
            src="/publications/miccai2024/miccai2024_v2.github.io-main/static/images/miccai2024_figure.png" 
            onmouseover="this.src='/publications/miccai2024/miccai2024_v2.github.io-main/static/images/miccai2024_figure2.png'" 
            onmouseout="this.src='/publications/miccai2024/miccai2024_v2.github.io-main/static/images/miccai2024_figure.png'" 
            class="img-fluid rounded float-center img-thumbnail shadow mb-3" 
            onmouseenter="zoomIn(event)" onmouseleave="zoomOut(event)" alt="Home" width="100%" hieght="100%">
          </div>
          <div class="col-lg-8">
            <h6><p class="publication_title">Multi-Modal Graph Neural Network with Transformer-Guided Adaptive Diffusion for Preclinical Alzheimer Classification</p></h6>
            <p class="text-muted"><b><u>Jaeyoon Sim</u></b>, Minjae Lee, Guorong Wu, Won Hwa Kim</p>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2024, Marrakesh, Morocco, 2024</p>
            <p>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#abs5_button" aria-expanded="false" aria-controls="abs5_button">Abstract</a>
              <a href="/publications/miccai2024/miccai2024_v2.github.io-main/index.html" target="_self" class="btn btn-outline-secondary btn-sm" role="button"> Project Page</a>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#bib5_button" aria-expanded="false" aria-controls="bib5_button">BibTeX</a>
            </p>
            <div class="collapse" id="abs5_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                The graphical representation of the brain offers critical insights into diagnosing and prognosing neurodegenerative 
                disease via relationships between regions of interest (ROIs). Despite recent emergence of various Graph Neural Networks 
                (GNNs) to effectively capture the relational information, there remain inherent limitations in interpreting the brain 
                networks. Specifically, convolutional approaches ineffectively aggregate information from distant neighborhoods, while 
                attention-based methods exhibit deficiencies in capturing node-centric information, particularly in retaining critical 
                characteristics from pivotal nodes. These shortcomings reveal challenges for identifying disease-specific variation 
                from diverse features from different modalities. In this regards, we propose an integrated framework guiding diffusion 
                process at each node by a downstream transformer where both short- and long-range properties of graphs are aggregated 
                via diffusion-kernel and multi-head attention respectively. We demonstrate the superiority of our model by improving 
                performance of pre-clinical Alzheimer’s disease (AD) classification with various modalities. Also, our model adeptly 
                identifies key ROIs that are closely associated with the preclinical stages of AD, marking a significant potential 
                for early diagnosis and prevision of the disease.
              </div>
            </div>
            <div class="collapse" id="bib5_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                @article{sim2024multi,<br>
                  author    = {Jaeyoon Sim and Minjae Lee and Guorong Wu and Won Hwa Kim},<br>
                  title     = {Multi-Modal Graph Neural Network with Transformer-Guided Adaptive Diffusion for Preclinical Alzheimer Classification},<br>
                  journal   = {MICCAI},<br>
                  year      = {2024}<br>
                  }
              </div>
            </div>
          </div>
          
          <div class="col-lg-4 text-center">
            <img id="publication_image"
            src="/publications/miccai2024/miccai2024_v1.github.io-main/static/images/miccai2024_figure.png" 
            onmouseover="this.src='/publications/miccai2024/miccai2024_v1.github.io-main/static/images/miccai2024_figure2.png'" 
            onmouseout="this.src='/publications/miccai2024/miccai2024_v1.github.io-main/static/images/miccai2024_figure.png'" 
            class="img-fluid rounded float-center img-thumbnail shadow mb-3" 
            onmouseenter="zoomIn(event)" onmouseleave="zoomOut(event)" alt="Home" width="100%" hieght="100%">
          </div>
          <div class="col-lg-8">
            <h6><p class="publication_title">OCL: Ordinal Contrastive Learning for Imputating Features with Progressive Labels</p></h6>
            <p class="text-muted">Seunghun Baek<sup>&#42;</sup>, <b><u>Jaeyoon Sim</u><sup>&#42;</sup></b>, Guorong Wu, Won Hwa Kim (<sup>&#42;</sup>: Equal Contribution)</p>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2024, Marrakesh, Morocco, 2024</p>
            <p style="color:rgb(187, 255, 184);">Provisional Accept [~11% Acceptance Rate]</p>
            <p>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#abs4_button" aria-expanded="false" aria-controls="abs4_button">Abstract</a>
              <a href="/publications/miccai2024/miccai2024_v1.github.io-main/index.html" target="_self" class="btn btn-outline-secondary btn-sm" role="button"> Project Page</a>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#bib4_button" aria-expanded="false" aria-controls="bib4_button">BibTeX</a>
            </p>
            <div class="collapse" id="abs4_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                Accurately discriminating progressive stages of Alzheimer’s Disease (AD) is crucial for 
                early diagnosis and prevention. It often involves multiple imaging modalities to understand 
                the complex pathology of AD, however, acquiring a complete set of images is challenging due 
                to high cost and burden for subjects. In the end, missing data become inevitable which lead
                to limited sample-size and decrease in precision in downstream analyses. To tackle this challenge, 
                we introduce a holistic imaging feature imputation method that enables to leverage diverse imaging 
                features while retaining all subjects. The proposed method comprises two networks: 1&#41; An encoder to 
                extract modality-independent embeddings and 2&#41; A decoder to reconstruct the original measures 
                conditioned on their imaging modalities. The encoder includes a novel ordinal contrastive loss, 
                which aligns samples in the embedding space according to the progression of AD. We also maximize 
                modality-wise coherence of embeddings within each subject, in conjunction with domain adversarial 
                training algorithms, to further enhance alignment between different imaging modalities. The proposed 
                method promotes our holistic imaging feature imputation across various modalities in the shared 
                embedding space. In the experiments, we show that our networks deliver favorable results for 
                statistical analysis and classification against imputation baselines with Alzheimer’s Disease 
                Neuroimaging Initiative (ADNI) study.
              </div>
            </div>
            <div class="collapse" id="bib4_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                @article{baek2024ocl,<br>
                  author    = {Seunghun Baek and Jaeyoon Sim and Guorong Wu and Won Hwa Kim},<br>
                  title     = {OCL: Ordinal Contrastive Learning for Imputating Features with Progressive Labels},<br>
                  journal   = {MICCAI},<br>
                  year      = {2024}<br>
                  }
              </div>
            </div>
          </div>

          <div class="col-lg-4 text-center">
            <img id="publication_image"
            src="/publications/icml2024/icml2024.github.io-main/static/images/icml2024_figure.png" 
            onmouseover="this.src='/publications/icml2024/icml2024.github.io-main/static/images/icml2024_figure3.png'" 
            onmouseout="this.src='/publications/icml2024/icml2024.github.io-main/static/images/icml2024_figure.png'" 
            class="img-fluid rounded float-center img-thumbnail shadow mb-3" 
            onmouseenter="zoomIn(event)" onmouseleave="zoomOut(event)" alt="Home" width="100%" hieght="100%">
          </div>
          <div class="col-lg-8">
            <h6><p class="publication_title">Neurodegenerative Brain Network Classification via Adaptive Diffusion with Temporal Regularization</p></h6>
            <p class="text-muted">Hyuna Cho, <b><u>Jaeyoon Sim</u></b>, Guorong Wu, Won Hwa Kim</p>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> International Conference on Machine Learning (ICML), Vienna, Austria, 2024</p>
            <p>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#abs3_button" aria-expanded="false" aria-controls="abs3_button">Abstract</a>
              <a href="/publications/icml2024/icml2024.github.io-main/index.html" target="_self" class="btn btn-outline-secondary btn-sm" role="button"> Project Page</a>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#bib3_button" aria-expanded="false" aria-controls="bib3_button">BibTeX</a>
            </p>
            <div class="collapse" id="abs3_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                Analysis of neurodegenerative diseases on brain connectomes is important in facilitating early 
                diagnosis and predicting its onset. However, investigation of the progressive and irreversible 
                dynamics of these diseases remains underexplored in cross-sectional studies as its diagnostic 
                groups are considered independent. Also, as in many real-world graphs, brain networks exhibit 
                intricate structures with both homophily and heterophily. To address these challenges, we propose 
                Adaptive Graph diffusion network with Temporal regularization (AGT). AGT introduces node-wise 
                convolution to adaptively capture low (i.e., homophily) and high-frequency (i.e., heterophily) 
                characteristics within an optimally tailored range for each node. Moreover, AGT captures sequential 
                variations within progressive diagnostic groups with a novel temporal regularization, considering 
                the relative feature distance between the groups in the latent space. As a result, our proposed 
                model yields interpretable results at both node-level and group-level. The superiority of our 
                method is validated on two neurodegenerative disease benchmarks for graph classification: Alzheimer’s 
                Disease Neuroimaging Initiative (ADNI) and Parkinson’s Progression Markers Initiative (PPMI) datasets.
              </div>
            </div>
            <div class="collapse" id="bib3_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                @article{cho2024neurodegenerative,<br>
                  author    = {Hyuna Cho and Jaeyoon Sim and Guorong Wu and Won Hwa Kim},<br>
                  title     = {Neurodegenerative Brain Network Classification via Adaptive Diffusion with Temporal Regularization},<br>
                  journal   = {ICML},<br>
                  year      = {2024}<br>
                  }
              </div>
            </div>
          </div>

          <div class="col-lg-4 text-center">
            <img id="publication_image"
            src="/publications/isbi2024/isbi2024.github.io-main/static/images/isbi2024_figure.png" 
            onmouseover="this.src='/publications/isbi2024/isbi2024.github.io-main/static/images/isbi2024_figure2.png'" 
            onmouseout="this.src='/publications/isbi2024/isbi2024.github.io-main/static/images/isbi2024_figure.png'" 
            class="img-fluid rounded float-center img-thumbnail shadow mb-3" 
            onmouseenter="zoomIn(event)" onmouseleave="zoomOut(event)" alt="Home" width="100%" hieght="100%">
          </div>
          <div class="col-lg-8">
            <h6><p class="publication_title">Modality-Agnostic Style Transfer for Holistic Feature Imputation</p></h6>
            <p class="text-muted">Seunghun Baek<sup>&#42;</sup>, <b><u>Jaeyoon Sim</u><sup>&#42;</sup></b>, Mustafa Dere, Minjeong Kim, Guorong Wu, Won Hwa Kim (<sup>&#42;</sup>: Equal Contribution)</p>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> International Symposium on Biomedical Imaging (ISBI), Athens, Greece, 2024</p>
            <p style="color:rgb(187, 255, 184);">Oral Presentation</p>
            <p>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#abs2_button" aria-expanded="false" aria-controls="abs2_button">Abstract</a>
              <a href="/publications/isbi2024/isbi2024.github.io-main/index.html" target="_self" class="btn btn-outline-secondary btn-sm" role="button"> Project Page</a>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#bib2_button" aria-expanded="false" aria-controls="bib2_button">BibTeX</a>
            </p>
            <div class="collapse" id="abs2_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                Characterizing a preclinical stage of Alzheimer’s Disease (AD) via single imaging is difficult as its 
                early symptoms are quite subtle. Therefore, many neuroimaging studies are curated with various imaging 
                modalities, e.g., MRI and PET, however, it is often challenging to acquire all of them from all subjects 
                and missing data become inevitable. In this regards, in this paper, we propose a framework that generates
                unobserved imaging measures for specific subjects using their existing measures, thereby reducing the need 
                for additional examinations. Our framework transfers modality-specific style while preserving AD-specific 
                content. This is done by domain adversarial training that preserves modality-agnostic but AD-specific 
                information, while a generative adversarial network adds an indistinguishable modality-specific style. 
                Our proposed framework is evaluated on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) study and 
                compared with other imputation methods in terms of generated data quality. Small average Cohen’s d < 0.19 
                between our generated measures and real ones suggests that the synthetic data are practically usable 
                regardless of their modality type.
              </div>
            </div>
            <div class="collapse" id="bib2_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                @article{baek2024modality,<br>
                  author    = {Seunghun Baek and Jaeyoon Sim and Mustafa Dere and Minjeong Kim and Guorong Wu and Won Hwa Kim},<br>
                  title     = {Modality-agnostic Style Transfer for Holistic Feature Imputation},<br>
                  journal   = {ISBI},<br>
                  year      = {2024}<br>
                  }
              </div>
            </div>
          </div>

          <div class="col-lg-4 text-center">
            <img id="publication_image"
            src="/publications/aaai2024/aaai2024.github.io-main/static/images/aaai2024_figure.png" 
            onmouseover="this.src='/publications/aaai2024/aaai2024.github.io-main/static/images/aaai2024_figure2.png'" 
            onmouseout="this.src='/publications/aaai2024/aaai2024.github.io-main/static/images/aaai2024_figure.png'" 
            class="img-fluid rounded float-center img-thumbnail shadow mb-3" 
            onmouseenter="zoomIn(event)" onmouseleave="zoomOut(event)" alt="Home" width="100%" hieght="100%">
          </div>
          <div class="col-lg-8">
            <h6><p class="publication_title">Learning to Approximate Adaptive Kernel Convolution on Graphs</p></h6>
            <p class="text-muted"><b><u>Jaeyoon Sim</u></b>, Sooyeon Jeon, InJun Choi, Guorong Wu, Won Hwa Kim</p>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> Association for the Advancement of Artificial Intelligence (AAAI), Vancouver, Canada, 2024. [23.75% Acceptance Rate]</p></span>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 3px 0px 3px; border-radius:20%"><b>W</b></span> Image Processing and Image Understanding (IPIU), Jeju, Korea, 2024</p>
            <p style="color:rgb(187, 255, 184);">IPIU Outstanding Paper Award - Bronze Prize</p>
            <p style="color:rgb(187, 255, 184);">BK21 Outstanding Paper Award - Excellence Prize</p>
            <p>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#abs1_button" aria-expanded="false" aria-controls="abs1_button">Abstract</a>
              <a href="/publications/aaai2024/aaai2024.github.io-main/index.html" target="_self" class="btn btn-outline-secondary btn-sm" role="button"> Project Page</a>
              <a class="btn btn-outline-secondary btn-sm" role="button" data-toggle="collapse" data-target="#bib1_button" aria-expanded="false" aria-controls="bib1_button">BibTeX</a>
            </p>
            <div class="collapse" id="abs1_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                Various Graph Neural Networks (GNNs) have been successful in analyzing data in non-Euclidean spaces, 
                however, they have limitations such as oversmoothing, i.e., information becomes excessively averaged 
                as the number of hidden layers increases. The issue stems from the intrinsic formulation of conventional 
                graph convolution where the nodal features are aggregated from a direct neighborhood per layer across 
                the entire nodes in the graph. As setting different number of hidden layers per node is infeasible, 
                recent works leverage a diffusion kernel to redefine the graph structure and incorporate information 
                from farther nodes. Unfortunately, such approaches suffer from heavy diagonalization of a graph Laplacian 
                or learning a large transform matrix. In this regards, we propose a diffusion learning framework where 
                the range of feature aggregation is controlled by the scale of a diffusion kernel. For efficient computation, 
                we derive closed-form derivatives of approximations of the graph convolution with respect to the scale, 
                so that node-wise range can be adaptively learned.With a downstream classifier, the entire framework is 
                made trainable in an end-to-end manner. Our model is tested on various standard datasets for node-wise 
                classification for the state-of-the-art performance, and it is also validated on a real-world brain network 
                data for graph classifications to demonstrate its practicality for Alzheimer classification.
              </div>
            </div>
            <div class="collapse" id="bib1_button">
              <div style="border: dashed 2px silver; line-height: 1.0em; background-color:rgb(46, 46, 46); color:white; text-align:justify" class="card card-body">
                @inproceedings{sim2024learning,<br>
                  title={Learning to Approximate Adaptive Kernel Convolution on Graphs},<br>
                  author={Sim, Jaeyoon and Jeon, Sooyeon and Choi, InJun and Wu, Guorong and Kim, Won Hwa},<br>
                  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},<br>
                  volume={38},<br>
                  number={5},<br>
                  pages={4882--4890},<br>
                  year={2024}<br>
                }
              </div>
            </div>
          </div> 
          
          
          
        </div>
      </div>
    </div>

  <!-- International Journal -->
    <div class="row g-5 mb-5">
      <div class="categorybar col-md-2">
        <h6>Domestic</h6>
        <!-- <i class="fas fa-spinner fa-spin"></i> -->
      </div>
      <div class="detail_publication col-md-10">
        <div class="row g-5 mb-5">

          <div class="col-lg-4 text-center">
            <img id="publication_image"
            src="/publications/ieie2023/images/ieie2023_figure.png" class="img-fluid rounded float-center img-thumbnail shadow mb-3" onmouseenter="zoomIn(event)" onmouseleave="zoomOut(event)">
          </div>
          <div class="col-lg-8">
            <h6><p class="publication_title">AI-Driven BGA Solder Joint Failure Detection  of PCB Assembly</h6>
            <p class="text-muted">Seunghun Baek, <b><u>Jaeyoon Sim</u></b>, Siyeon Park, Cheolung Yang, Songyi Jeon, Jongho Song, Won Hwa Kim</p>
            <p class="text-muted"><span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> Autumn Annual Conference of the Institute of Electronics and Information Engineers (IEIE), Siheung, Korea, 2023</p>
            <!--
            <p>
            <a href="/publications/xx.pdf" target="_blank" class="btn btn-outline-secondary btn-sm" role="button"> Paper</a>
            <a href="/publications/cvpr2023/xx.html" target="_blank" class="btn btn-outline-secondary btn-sm" role="button"> BibTeX</a>
            <a href="/publications/cvpr2023/CVPR2023_supplementary/xx.html" target="_blank" class="btn btn-outline-secondary btn-sm" role="button"> Supplementary</a>
            </p>
            -->
          </div>

        </div>

      </div>

      <div>
        <p style="text-align:right">
        <span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 5px 0px 5px; border-radius:20%"><b>C</b></span> : Conference &nbsp; &nbsp;
        <span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 7px 0px 7px; border-radius:20%"><b>J</b></span> : Journal &nbsp; &nbsp;
        <span style="background-color:rgb(187, 255, 184); color:rgb(0, 120, 0); padding: 0px 3px 0px 3px; border-radius:20%"><b>W</b></span> : Workshop 
        </p>
      </div>
    </div>
  
  </div>
</div>

      <footer class="pt-3 my-5 text-muted border-top">
  <div class="row">
    <div class="col-md-12 social-media-icons">
    
      <a class="home_name" style="text-decoration:none">Seize the day, Carpe diem!</a>

      <a href="https://velog.io/@claude_ssim" class="ms-3 fs-5" style="float:right"><i class="fas fa-blog"></i></a>
      
        <a href="https://github.com/JaeyoonSSim" class="ms-3 fs-5" style="float:right"><i class="fab fa-github"></i></a>
      
        <a href="https://www.linkedin.com/in/jaeyoon-sim-86a4aa185/" class="ms-3 fs-5" style="float:right"><i class="fab fa-linkedin"></i></a>
      
        <a href="https://scholar.google.com/citations?user=XheFLZgAAAAJ&hl=ko" class="ms-3 fs-5" style="float:right"><i class="fab fa-google scholar"></i></a>
      
      
    </div>
    <p class="copyright text-center">&copy; Jaeyoon Sim 2021-2024</p>
  </div>
</footer>

    </div>

  </body>
</html>
